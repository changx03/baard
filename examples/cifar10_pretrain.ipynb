{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision as tv\n",
    "from pl_bolts.transforms import dataset_normalizations\n",
    "from pytorch_lightning import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 123\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_everything(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: /home/lukec/workspace/baard_v4/data\n"
     ]
    }
   ],
   "source": [
    "# `data` folder should be under the project root directory.\n",
    "PATH_ROOT = Path(os.getcwd()).absolute().parent\n",
    "PATH_DATASETS = os.path.join(PATH_ROOT, 'data')\n",
    "print('Data path:', PATH_DATASETS)\n",
    "\n",
    "BATCH_SIZE = 256 if torch.cuda.is_available() else 64\n",
    "NUM_WORKERS = os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = tv.transforms.Compose([\n",
    "    tv.transforms.RandomCrop(32, padding=4),\n",
    "    tv.transforms.RandomHorizontalFlip(),\n",
    "    tv.transforms.ToTensor(),\n",
    "    dataset_normalizations.cifar10_normalization(),\n",
    "])\n",
    "\n",
    "transform_test = tv.transforms.Compose([\n",
    "    tv.transforms.ToTensor(),\n",
    "    dataset_normalizations.cifar10_normalization(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_train = tv.datasets.CIFAR10(PATH_DATASETS, train=True, download=True, transform=transform_train)\n",
    "dataset_test = tv.datasets.CIFAR10(PATH_DATASETS, train=False, download=True, transform=transform_test)\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "loader_test = DataLoader(dataset_test, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tv.models.resnet18(weights=None, num_classes=10)\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "ResNet                                   [256, 10]                 --\n",
       "├─Conv2d: 1-1                            [256, 64, 32, 32]         1,728\n",
       "├─BatchNorm2d: 1-2                       [256, 64, 32, 32]         128\n",
       "├─ReLU: 1-3                              [256, 64, 32, 32]         --\n",
       "├─Identity: 1-4                          [256, 64, 32, 32]         --\n",
       "├─Sequential: 1-5                        [256, 64, 32, 32]         --\n",
       "│    └─BasicBlock: 2-1                   [256, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-1                  [256, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-2             [256, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-3                    [256, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-4                  [256, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-5             [256, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-6                    [256, 64, 32, 32]         --\n",
       "│    └─BasicBlock: 2-2                   [256, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-7                  [256, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-8             [256, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-9                    [256, 64, 32, 32]         --\n",
       "│    │    └─Conv2d: 3-10                 [256, 64, 32, 32]         36,864\n",
       "│    │    └─BatchNorm2d: 3-11            [256, 64, 32, 32]         128\n",
       "│    │    └─ReLU: 3-12                   [256, 64, 32, 32]         --\n",
       "├─Sequential: 1-6                        [256, 128, 16, 16]        --\n",
       "│    └─BasicBlock: 2-3                   [256, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-13                 [256, 128, 16, 16]        73,728\n",
       "│    │    └─BatchNorm2d: 3-14            [256, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-15                   [256, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-16                 [256, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-17            [256, 128, 16, 16]        256\n",
       "│    │    └─Sequential: 3-18             [256, 128, 16, 16]        8,448\n",
       "│    │    └─ReLU: 3-19                   [256, 128, 16, 16]        --\n",
       "│    └─BasicBlock: 2-4                   [256, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-20                 [256, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-21            [256, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-22                   [256, 128, 16, 16]        --\n",
       "│    │    └─Conv2d: 3-23                 [256, 128, 16, 16]        147,456\n",
       "│    │    └─BatchNorm2d: 3-24            [256, 128, 16, 16]        256\n",
       "│    │    └─ReLU: 3-25                   [256, 128, 16, 16]        --\n",
       "├─Sequential: 1-7                        [256, 256, 8, 8]          --\n",
       "│    └─BasicBlock: 2-5                   [256, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-26                 [256, 256, 8, 8]          294,912\n",
       "│    │    └─BatchNorm2d: 3-27            [256, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-28                   [256, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-29                 [256, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-30            [256, 256, 8, 8]          512\n",
       "│    │    └─Sequential: 3-31             [256, 256, 8, 8]          33,280\n",
       "│    │    └─ReLU: 3-32                   [256, 256, 8, 8]          --\n",
       "│    └─BasicBlock: 2-6                   [256, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-33                 [256, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-34            [256, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-35                   [256, 256, 8, 8]          --\n",
       "│    │    └─Conv2d: 3-36                 [256, 256, 8, 8]          589,824\n",
       "│    │    └─BatchNorm2d: 3-37            [256, 256, 8, 8]          512\n",
       "│    │    └─ReLU: 3-38                   [256, 256, 8, 8]          --\n",
       "├─Sequential: 1-8                        [256, 512, 4, 4]          --\n",
       "│    └─BasicBlock: 2-7                   [256, 512, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-39                 [256, 512, 4, 4]          1,179,648\n",
       "│    │    └─BatchNorm2d: 3-40            [256, 512, 4, 4]          1,024\n",
       "│    │    └─ReLU: 3-41                   [256, 512, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-42                 [256, 512, 4, 4]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-43            [256, 512, 4, 4]          1,024\n",
       "│    │    └─Sequential: 3-44             [256, 512, 4, 4]          132,096\n",
       "│    │    └─ReLU: 3-45                   [256, 512, 4, 4]          --\n",
       "│    └─BasicBlock: 2-8                   [256, 512, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-46                 [256, 512, 4, 4]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-47            [256, 512, 4, 4]          1,024\n",
       "│    │    └─ReLU: 3-48                   [256, 512, 4, 4]          --\n",
       "│    │    └─Conv2d: 3-49                 [256, 512, 4, 4]          2,359,296\n",
       "│    │    └─BatchNorm2d: 3-50            [256, 512, 4, 4]          1,024\n",
       "│    │    └─ReLU: 3-51                   [256, 512, 4, 4]          --\n",
       "├─AdaptiveAvgPool2d: 1-9                 [256, 512, 1, 1]          --\n",
       "├─Linear: 1-10                           [256, 10]                 5,130\n",
       "==========================================================================================\n",
       "Total params: 11,173,962\n",
       "Trainable params: 11,173,962\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 142.19\n",
       "==========================================================================================\n",
       "Input size (MB): 3.15\n",
       "Forward/backward pass size (MB): 2516.60\n",
       "Params size (MB): 44.70\n",
       "Estimated Total Size (MB): 2564.44\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "i = iter(dataset_train)\n",
    "x, y = next(i)\n",
    "input_size = tuple([BATCH_SIZE] + list(x.size()))\n",
    "summary(model, input_size=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from pytorch_lightning import LightningModule\n",
    "\n",
    "\n",
    "class LitResnet(LightningModule):\n",
    "    def __init__(self, lr):\n",
    "        super().__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.model = create_model()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        outputs = self.model(x)\n",
    "        preds = outputs.argmax(dim=-1)\n",
    "        loss = self.loss_fn(outputs, y)\n",
    "        acc = (preds == y).float().mean()\n",
    "        self.log(\"train_acc\", acc, on_step=False, on_epoch=True)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def evaluate(self, batch, stage=None):\n",
    "        x, y = batch\n",
    "        outputs = self.model(x)\n",
    "        preds = outputs.argmax(dim=-1)\n",
    "        loss = self.loss_fn(outputs, y)\n",
    "        acc = (preds == y).float().mean()\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f\"{stage}_loss\", loss)\n",
    "            self.log(f\"{stage}_acc\", acc)\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.evaluate(batch, \"test\")\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.hparams.lr,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-4,\n",
    "        )\n",
    "        steps_per_epoch = len(loader_train)\n",
    "        scheduler_dict = {\n",
    "            \"scheduler\": OneCycleLR(\n",
    "                optimizer,\n",
    "                0.1,\n",
    "                epochs=self.trainer.max_epochs,\n",
    "                steps_per_epoch=len(loader_train),\n",
    "            ),\n",
    "            \"interval\": \"step\",\n",
    "        }\n",
    "        return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.progress import TQDMProgressBar\n",
    "\n",
    "LEARNING_RATE = 0.05\n",
    "MAX_EPOCHS = 5\n",
    "PATH_LOG = os.path.join(PATH_ROOT, 'logs')\n",
    "MODEL_NAME = 'cifar10-resnet18'\n",
    "PATH_CHECKPOINT = os.path.join(PATH_ROOT, 'pretrained_models')\n",
    "PATH_MODEL = os.path.join(PATH_CHECKPOINT, MODEL_NAME)\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator=\"auto\",\n",
    "    devices=1 if torch.cuda.is_available() else None,  # limiting got iPython runs\n",
    "    logger=CSVLogger(save_dir=PATH_CHECKPOINT),\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "        LearningRateMonitor(logging_interval=\"step\"),\n",
    "        TQDMProgressBar(refresh_rate=10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type             | Params | In sizes       | Out sizes\n",
      "--------------------------------------------------------------------------\n",
      "0 | model   | ResNet           | 11.2 M | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_fn | CrossEntropyLoss | 0      | ?              | ?        \n",
      "--------------------------------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf60beb96a04a86a6de55f13dfff508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a387a04ad94cf1898f17c3c6e99903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukec/workspace/baard_v4/venv/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:653: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fed213b07f4cd0a2cc178081ca6afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "        test_acc             0.453000009059906\n",
      "        test_loss           1.4720160961151123\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 1.4720160961151123, 'test_acc': 0.453000009059906}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_filename = os.path.join(PATH_MODEL + \".ckpt\")\n",
    "if os.path.isfile(pretrained_filename):\n",
    "    model = LitResnet.load_from_checkpoint(pretrained_filename)\n",
    "else:\n",
    "    model = LitResnet(lr=LEARNING_RATE)\n",
    "    trainer.fit(model, train_dataloaders=loader_train, val_dataloaders=loader_test)\n",
    "\n",
    "trainer.test(model, dataloaders=loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "\n",
    "metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\n",
    "del metrics[\"step\"]\n",
    "metrics.set_index(\"epoch\", inplace=True)\n",
    "display(metrics.dropna(axis=1, how=\"all\").head())\n",
    "sn.relplot(data=metrics, kind=\"line\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = trainer.predict(model, loader_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca1e3ec0254efb300f2de71f1d983378da29e4ede80290b822db9c2199a6e419"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
